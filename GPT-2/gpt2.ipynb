{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3472931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cohlem/anaconda3/envs/deep_learning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07acab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "['c_attn.weight', 'c_proj.weight','c_fc.weight', 'c_proj.weight', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0773811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef2c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ad317a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model, I'm doing some work with a lot. I see how many of you are wondering why you are doing this\n",
      "> Hello, I'm a language model, what can I say?\n",
      "\n",
      "\n",
      "Of course its own I am. This model is something entirely separate from\n",
      "> Hello, I'm a language model, please tell my friends about the world.\n",
      "\n",
      "Merry Jesus, I hope you get on here soon.\n",
      "> Hello, I'm a language model, I hope you will find out how to do \"I am here!\" useful in the next week.\"\n",
      "\n",
      "\n",
      "> Hello, I'm a language model, my daughter's not a model. And our best friend here in the world is actually a bad language model,\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3*config.n_embd)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.block_size, config.block_size)))\n",
    "        self.n_embd = config.n_embd\n",
    "        self.n_head = config.n_head\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        qkv = self.c_attn(x)\n",
    "        \n",
    "        Q,K,V = torch.split(qkv,self.n_embd,dim=-1)\n",
    "\n",
    "        \n",
    "        # comment out if using multi head attention\n",
    "        ### ------ multi-head ----------------\n",
    "        assert self.n_embd // self.n_head, 'n_embd and n_head dont comply'\n",
    "        h_dim = self.n_embd // self.n_head\n",
    "        \n",
    "        Q = Q.view(B,T,self.n_head, h_dim)\n",
    "        K = K.view(B,T,self.n_head, h_dim)\n",
    "        V = V.view(B,T,self.n_head, h_dim)\n",
    "        \n",
    "        Q = torch.transpose(Q, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        K = torch.transpose(K, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        V = torch.transpose(V, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        \n",
    "        ### ------ multi-head ----------------\n",
    "        aw = Q @ torch.transpose(K, -2,-1) # for matmul dim of q should be B,T,C and k should be B,C,T\n",
    "        with torch.no_grad():\n",
    "            global check\n",
    "            check = aw.clone()\n",
    "        aw = aw/(K.shape[-2] **0.5)\n",
    "        mask = self.tril[:T,:T] == 0 # generate mask\n",
    "        aw = aw.masked_fill_(mask, float('-inf')) # apply mask i.e fill true values with -inf \n",
    "        aw = torch.softmax(aw,dim=-1) # -inf values are converted to 0 and then each row is normalized\n",
    "\n",
    "        cv = aw @ V # context vector\n",
    "        cv = torch.transpose(cv, 1,2) # bring it back to (B,T,n_heads, h_dim)\n",
    "        cv = cv.contiguous().view(B,T,-1)\n",
    "        cv = self.c_proj(cv)\n",
    "        return cv\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4*config.n_embd)\n",
    "        self.c_proj = nn.Linear(4*config.n_embd, config.n_embd)\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.attn = Head(config)\n",
    "        self.mlp = FFN(config)\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.attn(self.ln_1(x)) + x\n",
    "        x = self.mlp(self.ln_2(x)) + x\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    vocab_size : int = 50257\n",
    "    n_layer : int = 12\n",
    "    n_embd : int = 768\n",
    "    n_head : int= 12\n",
    "    block_size :int = 1024\n",
    "    \n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict({\n",
    "            'wte' : nn.Embedding(self.config.vocab_size,self.config.n_embd),\n",
    "            'wpe' : nn.Embedding(self.config.block_size, self.config.n_embd ),\n",
    "            'h' : nn.ModuleList([Block(self.config) for _ in range(self.config.n_layer)]),\n",
    "            'ln_f' : nn.LayerNorm(self.config.n_embd)\n",
    "        })\n",
    "        self.lm_head = nn.Linear(self.config.n_embd, self.config.vocab_size, bias=False)\n",
    "        \n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.size()\n",
    "        loss = None\n",
    "\n",
    "        x_embd = self.transformer.wte(x)\n",
    "#         pos = torch.arange(x.shape[1])\n",
    "        pos = torch.arange(0, T, dtype=torch.long)\n",
    "    \n",
    "        x_pe = self.transformer.wpe(pos)\n",
    "        \n",
    "        x = x_embd + x_pe\n",
    "        \n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = nn.functional.cross_entropy(logits,targets)\n",
    "\n",
    "        return logits\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def from_pretrained(cls,model_type):\n",
    "        config = GPTConfig()\n",
    "        model = GPT(config)\n",
    "        \n",
    "        sd = model.state_dict()\n",
    "        sd_keys = model.state_dict().keys()\n",
    "        \n",
    "        sd_keys = [key for key in sd_keys if not key.endswith('.attn.tril')]\n",
    "        \n",
    "        from transformers import GPT2LMHeadModel\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "    \n",
    "        sd_hf = model_hf.state_dict()\n",
    "        sd_hf_keys = model_hf.state_dict().keys()\n",
    "        \n",
    "        assert len(sd_keys) == len(sd_hf_keys), 'keys unmatched, please make sure the length of keys matches'\n",
    "        \n",
    "        transposed = ['.attn.c_attn.weight', '.attn.c_proj.weight','.mlp.c_fc.weight', '.mlp.c_proj.weight', ]\n",
    "        for k,v in sd_hf.items():\n",
    "            for i in transposed:\n",
    "                if k.endswith(i):\n",
    "                    sd_hf[k] = sd_hf[k].t()\n",
    "            with torch.no_grad():\n",
    "#                 print(k)\n",
    "#                 print(sd[k].shape, sd_hf[k].shape)\n",
    "                sd[k].copy_(sd_hf[k])\n",
    "\n",
    "                    \n",
    "        return model\n",
    "    \n",
    "    \n",
    "# -----------------------------------------------------------------------------\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "\n",
    "model = GPT.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "# model.to('cuda')\n",
    "\n",
    "# prefix tokens\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
    "x = tokens\n",
    "\n",
    "# generate! right now x is (B, T) where B = 5, T = 8\n",
    "# set the seed to 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "while x.size(1) < max_length:\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x) # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = x[i, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dad31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10dea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127e32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601e749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2781d149",
   "metadata": {},
   "source": [
    "### Edit this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc9d804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6b248bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 214\u001b[0m\n\u001b[1;32m    212\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x) \u001b[38;5;66;03m# (B, T, vocab_size)\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# take the logits at the last position\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# (B, vocab_size)\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# get the probabilities\u001b[39;00m\n\u001b[1;32m    216\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3*config.n_embd)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        self.n_embd = config.n_embd\n",
    "        self.n_head = config.n_head\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        qkv = self.c_attn(x)\n",
    "        \n",
    "        Q,K,V = qkv.split(self.n_embd, dim=2)\n",
    "\n",
    "        \n",
    "        # comment out if using multi head attention\n",
    "        ### ------ multi-head ----------------\n",
    "        assert self.n_embd // self.n_head, 'n_embd and n_head dont comply'\n",
    "        h_dim = self.n_embd // self.n_head\n",
    "        \n",
    "        Q = Q.view(B, T, self.n_head, C // self.n_head)\n",
    "        K = K.view(B, T, self.n_head, C // self.n_head)\n",
    "        V = V.view(B, T, self.n_head, C // self.n_head)\n",
    "        Q = torch.transpose(Q, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        K = torch.transpose(K, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        V = torch.transpose(V, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        \n",
    "        ### ------ multi-head ----------------\n",
    "#         aw = (Q @ torch.transpose(K, -2,-1) * (1.0 / math.sqrt(K.size(-1)))) # for matmul dim of q should be B,T,C and k should be B,C,T\n",
    "        \n",
    "        aw = (Q @ torch.transpose(K, -2,-1)) # for matmul dim of q should be B,T,C and k should be B,C,T\n",
    "        aw = aw/(K.shape[-1] **0.5)\n",
    "        mask = self.tril[:,:,:T,:T] == 0 # generate mask\n",
    "        aw = aw.masked_fill_(mask, float('-inf')) # apply mask i.e fill true values with -inf \n",
    "        aw = torch.softmax(aw,dim=-1) # -inf values are converted to 0 and then each row is normalized\n",
    "\n",
    "        cv = aw @ V # context vector\n",
    "        cv = torch.transpose(cv, 1,2) # bring it back to (B,T,n_heads, h_dim)\n",
    "        cv = cv.contiguous().view(B,T,C)\n",
    "        cv = self.c_proj(cv)\n",
    "        return cv\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4*config.n_embd)\n",
    "        self.c_proj = nn.Linear(4*config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.attn = Head(config)\n",
    "        self.mlp = FFN(config)\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.attn(self.ln_1(x)) + x\n",
    "        x = self.mlp(self.ln_2(x)) + x\n",
    "    \n",
    "        return x\n",
    "\n",
    "    \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    vocab_size : int = 50257\n",
    "    n_layer : int = 12\n",
    "    n_embd : int = 768\n",
    "    n_head : int= 12\n",
    "    block_size :int = 1024\n",
    "    \n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict({\n",
    "            'wte' : nn.Embedding(self.config.vocab_size,self.config.n_embd),\n",
    "            'wpe' : nn.Embedding(self.config.block_size, self.config.n_embd ),\n",
    "            'h' : nn.ModuleList([Block(self.config) for _ in range(self.config.n_layer)]),\n",
    "            'ln_f' : nn.LayerNorm(self.config.n_embd)\n",
    "        })\n",
    "        self.lm_head = nn.Linear(self.config.n_embd, self.config.vocab_size, bias=False)\n",
    "        \n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.size()\n",
    "        loss = None\n",
    "\n",
    "        x_embd = self.transformer.wte(x)\n",
    "#         pos = torch.arange(x.shape[1])a\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=x.device)\n",
    "    \n",
    "        x_pe = self.transformer.wpe(pos)\n",
    "        \n",
    "        x = x_embd + x_pe\n",
    "        \n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = nn.functional.cross_entropy(logits,targets)\n",
    "\n",
    "        return logits,loss\n",
    "        \n",
    "    def _init_weights(self,module):\n",
    "        \n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                std *= (2*self.config.n_layer)**-0.5\n",
    "                \n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std=std)\n",
    "            \n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        \n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std=0.02)\n",
    "            \n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls,model_type):\n",
    "        config = GPTConfig()\n",
    "        model = GPT(config)\n",
    "        \n",
    "        sd = model.state_dict()\n",
    "        sd_keys = model.state_dict().keys()\n",
    "        \n",
    "        sd_keys = [key for key in sd_keys if not key.endswith('.attn.tril')]\n",
    "        \n",
    "        from transformers import GPT2LMHeadModel\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "    \n",
    "        sd_hf = model_hf.state_dict()\n",
    "        sd_hf_keys = model_hf.state_dict().keys()\n",
    "        \n",
    "        assert len(sd_keys) == len(sd_hf_keys), 'keys unmatched, please make sure the length of keys matches'\n",
    "        \n",
    "        transposed = ['.attn.c_attn.weight', '.attn.c_proj.weight','.mlp.c_fc.weight', '.mlp.c_proj.weight', ]\n",
    "        for k,v in sd_hf.items():\n",
    "            for i in transposed:\n",
    "                if k.endswith(i):\n",
    "                    sd_hf[k] = sd_hf[k].t()\n",
    "            with torch.no_grad():\n",
    "#                 print(k)\n",
    "#                 print(sd[k].shape, sd_hf[k].shape)\n",
    "                sd[k].copy_(sd_hf[k])\n",
    "\n",
    "                    \n",
    "        return model\n",
    "    \n",
    "start_time = time.time()\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "\n",
    "model = GPT.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# prefix tokens\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"My name is cutie siza\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
    "x = tokens.to(device)\n",
    "\n",
    "# generate! right now x is (B, T) where B = 5, T = 8\n",
    "# set the seed to 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "while x.size(1) < max_length:\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x) # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = x[i, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "## ------------------ Train ---------------- ##\n",
    "\n",
    "\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7d4ba",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0287bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "\n",
    "        # at init load tokens from disk and store them in memory\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B * T)} batches\")\n",
    "\n",
    "        # state\n",
    "        self.current_position = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "        # advance the position in the tensor\n",
    "        self.current_position += B * T\n",
    "        # if loading the next batch would be out of bounds, reset\n",
    "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoaderLite(B=4, T=32)\n",
    "\n",
    "# get logits\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "\n",
    "# optimize!\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "for i in range(50):\n",
    "    x, y = train_loader.next_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"step {i}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b6668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a444d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6dfaeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 6e-4\n",
    "min_lr = max_lr * 0.1\n",
    "warmup_steps = 10\n",
    "max_steps = 50\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_steps:\n",
    "        return max_lr * (it+1) / warmup_steps\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > max_steps:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
    "    return min_lr + coeff * (max_lr - min_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bbb9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ls = []\n",
    "for i in range(200):\n",
    "    ls.append(get_lr(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70dd3d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x281bbef60>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ba940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ac79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc7ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1134d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9612462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50765473",
   "metadata": {},
   "source": [
    "### karpathy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f11966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58bfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856456aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff8b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb38943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d7c3fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x111e309b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4fb7943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The White man worked as a bus driver in Houston'},\n",
       " {'generated_text': 'The White man worked as a journalist and producer of'},\n",
       " {'generated_text': 'The White man worked as a detective in the White'},\n",
       " {'generated_text': 'The White man worked as a waiter and a bar'},\n",
       " {'generated_text': 'The White man worked as a waitress at the restaurant'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "generator(\"The White man worked as a\", max_length=10, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357522d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9add83d0",
   "metadata": {},
   "source": [
    "### My implementation to load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self,h_dim):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.wk = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.wv = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        Q,K,V = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        \n",
    "        # comment out if using multi head attention\n",
    "        ### ------ multi-head ----------------\n",
    "        n_heads = emb_dim // h_dim\n",
    "        Q = Q.view(B,T,n_heads, h_dim)\n",
    "        K = K.view(B,T,n_heads, h_dim)\n",
    "        V = V.view(B,T,n_heads, h_dim)\n",
    "        \n",
    "        Q = torch.transpose(Q, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        K = torch.transpose(K, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        V = torch.transpose(V, 1,2) # transposing (n_head, block_size) cause we'll do matmul operation on block_size and h_dim\n",
    "        \n",
    "        ### ------ multi-head ----------------\n",
    "        aw = Q @ torch.transpose(K, -2,-1) # for matmul dim of q should be B,T,C and k should be B,C,T\n",
    "        aw = aw/(emb_dim **0.5)\n",
    "        mask = self.tril[:T,:T] == 0 # generate mask\n",
    "        aw = aw.masked_fill_(mask, float('-inf')) # apply mask i.e fill true values with -inf \n",
    "        aw = torch.softmax(aw,dim=-1) # -inf values are converted to 0 and then each row is normalized\n",
    "\n",
    "        cv = aw @ V # context vector\n",
    "        cv = torch.transpose(cv, 1,2) # bring it back to (B,T,n_heads, h_dim)\n",
    "        cv = cv.contiguous().view(B,T,-1)\n",
    "        \n",
    "        return cv\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2f203f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Linear(3,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e5e622c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32,8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "251e4ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ans \u001b[38;5;241m=\u001b[39m l(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "ans = l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a70f7385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 3])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f9a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
