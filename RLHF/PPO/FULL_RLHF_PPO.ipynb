{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6aebf38be9c048a4a5d974a439ba95ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9e7319712f143dfa266a314eb9c3d3b",
              "IPY_MODEL_0a92dd8e1d6a4658b346c9209b52fa3c",
              "IPY_MODEL_115337d3575f4d9fbb0b55826238d446"
            ],
            "layout": "IPY_MODEL_88132f5d96b04f8c9559045bfa1cba45"
          }
        },
        "d9e7319712f143dfa266a314eb9c3d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675bb40624a14ae0bb3e97bda3b9f9a7",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb0499b2aca43838ec3f7e042a29a1b",
            "value": "Map: 100%"
          }
        },
        "0a92dd8e1d6a4658b346c9209b52fa3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e65e2c634eb4483db149e8b7ba631dbe",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7614ff0a290b413c9e06ddd143cc5f0b",
            "value": 20
          }
        },
        "115337d3575f4d9fbb0b55826238d446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f39369381e4c1e87e6a217f9ad02c3",
            "placeholder": "​",
            "style": "IPY_MODEL_dd76e8908fbf439a8da6ce103d9e0595",
            "value": " 20/20 [00:00&lt;00:00, 207.54 examples/s]"
          }
        },
        "88132f5d96b04f8c9559045bfa1cba45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675bb40624a14ae0bb3e97bda3b9f9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb0499b2aca43838ec3f7e042a29a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e65e2c634eb4483db149e8b7ba631dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7614ff0a290b413c9e06ddd143cc5f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5f39369381e4c1e87e6a217f9ad02c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd76e8908fbf439a8da6ce103d9e0595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets -q"
      ],
      "metadata": {
        "id": "lP5E9TNGYPxl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pOejqXBUWO_7"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_dataset = load_dataset('imdb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrxfz2DkYKfT",
        "outputId": "65bd812b-4eda-4976-d4b4-eaa1b7f9679e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "\n",
        "model_name = 'EKKam/opt-1.5b_imdb_sft'\n",
        "# model_name = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtJXFzgYYij_",
        "outputId": "8b57757c-e72e-4156-c1a9-bd377b546129"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "NhJoTfU1r4_P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "# Sample input batch\n",
        "batch_texts = [\n",
        "    \"Once upon a time there was a ghost in the town\",\n",
        "    \"In a galaxy far, far away there lies a star that is \",\n",
        "    \"He was a good boy. He did all his homework in time \"\n",
        "]\n",
        "\n",
        "# Tokenize input batch and prepare for generation\n",
        "inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, padding_side='left', max_length=5).to(device)\n",
        "\n",
        "# Generate sequences in batch\n",
        "# You can customize parameters such as max_length, num_return_sequences, etc.\n",
        "# generated_outputs = model.generate(\n",
        "#     **inputs,\n",
        "#     max_length=512,\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "HmUXP8Zfr2Dd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_outputs = [tokenizer.decode(output, skip_special_tokens=True) for output in generated_outputs]"
      ],
      "metadata": {
        "id": "mMY_l8VVsv3I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = torch.tensor(tokenizer.encode(tokenizer.pad_token)).to(device)"
      ],
      "metadata": {
        "id": "fR97_0L8tgDf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5b6_41UKCX_",
        "outputId": "28b46807-7bd6-4720-f32f-1c98c1df91dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5MaUbp0KPEQ",
        "outputId": "89418454-e55a-42ba-fcdb-94f255192238"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = generated_outputs.ne(torch.tensor([tokenizer.pad_token_id]).to(device))"
      ],
      "metadata": {
        "id": "BvXjlcV-tKml"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(generated_outputs[0])"
      ],
      "metadata": {
        "id": "haJpcYa_uEuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Dk477iknt-Cv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask.sum(dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iaRRAI2tu9T",
        "outputId": "c3a438af-c76d-4eea-edca-522a466e06de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([509, 512, 511], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSpBJ4ePyv3L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_id = generated_outputs[:1, :]\n",
        "attention_mask_one = attention_mask[:1, :]"
      ],
      "metadata": {
        "id": "9sFAnJ-kwwK7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4j0G-Z7Ryl8B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = model(input_ids = inp_id, attention_mask = attention_mask_one)"
      ],
      "metadata": {
        "id": "C_gHyez8ZvJk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Agent(nn.Module):\n",
        "  def __init__(self,model,embd_dim, dropout=0.0):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.value_head = nn.Sequential(\n",
        "            nn.LayerNorm(embd_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embd_dim, 4*embd_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4*embd_dim, 1),\n",
        "        )\n",
        "\n",
        "  def generate(self, **x):\n",
        "    return self.model.generate(**x, max_new_tokens=512)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.model(x, output_hidden_states=True).hidden_states # this outputs hidden state for each transformer layer\n",
        "    last_hidden_state = out[-1] #(B,T,C)\n",
        "    logits = self.model.lm_head(last_hidden_state) # (B,T,vocab_length)\n",
        "\n",
        "    value = self.value_head(last_hidden_state) #(B,T,1)\n",
        "    return logits, value\n"
      ],
      "metadata": {
        "id": "hnbB5Yjm4zyu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "aPvJd8bfG18x"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhxytwpIH-OY",
        "outputId": "2f2c0baa-1c46-4859-cac1-025a48415dce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"_remove_final_layer_norm\": false,\n",
              "  \"activation_dropout\": 0.0,\n",
              "  \"activation_function\": \"relu\",\n",
              "  \"architectures\": [\n",
              "    \"OPTForCausalLM\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 2,\n",
              "  \"do_layer_norm_before\": true,\n",
              "  \"dropout\": 0.1,\n",
              "  \"enable_bias\": true,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"ffn_dim\": 8192,\n",
              "  \"hidden_size\": 2048,\n",
              "  \"init_std\": 0.02,\n",
              "  \"layer_norm_elementwise_affine\": true,\n",
              "  \"layerdrop\": 0.0,\n",
              "  \"max_position_embeddings\": 2048,\n",
              "  \"model_type\": \"opt\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 24,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"prefix\": \"</s>\",\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.51.3\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50272,\n",
              "  \"word_embed_proj_dim\": 2048\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(model,model.config.hidden_size).to(device)"
      ],
      "metadata": {
        "id": "VHME4Wff4zvm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(item):\n",
        "  tokenized_data = tokenizer(item['text'], return_tensors='pt', add_special_tokens=True, max_length=40, truncation=True)\n",
        "  item['input_ids'] = tokenized_data['input_ids'].squeeze()\n",
        "  item['attention_mask'] = tokenized_data['attention_mask'].squeeze()\n",
        "\n",
        "  return item\n"
      ],
      "metadata": {
        "id": "NZxXjyBTa4GT"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_dataset['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sudkD0gle102",
        "outputId": "5c06148d-bcd0-4351-d0aa-d95eb1981cb9"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_db = Dataset.from_dict(imdb_dataset['train'][:20])\n",
        "exp_tokenized = exp_db.map(tokenize_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6aebf38be9c048a4a5d974a439ba95ca",
            "d9e7319712f143dfa266a314eb9c3d3b",
            "0a92dd8e1d6a4658b346c9209b52fa3c",
            "115337d3575f4d9fbb0b55826238d446",
            "88132f5d96b04f8c9559045bfa1cba45",
            "675bb40624a14ae0bb3e97bda3b9f9a7",
            "1bb0499b2aca43838ec3f7e042a29a1b",
            "e65e2c634eb4483db149e8b7ba631dbe",
            "7614ff0a290b413c9e06ddd143cc5f0b",
            "e5f39369381e4c1e87e6a217f9ad02c3",
            "dd76e8908fbf439a8da6ce103d9e0595"
          ]
        },
        "id": "UTaq3N4_eswX",
        "outputId": "371d23c8-3a19-4816-ac3c-06e4f0e38cfd"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aebf38be9c048a4a5d974a439ba95ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_tokenized['attention_mask'][:2]\n",
        "\n",
        "sample_input = {'input_ids' : torch.tensor(exp_tokenized['input_ids'][:2]), 'attention_mask' : torch.tensor(exp_tokenized['attention_mask'][:2])}"
      ],
      "metadata": {
        "id": "sUHOTF-xcxgj"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input['input_ids'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoGLJEIEPk7E",
        "outputId": "1fd13a99-f11e-45da-dddd-50e9228fc619"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rR22p7fHPL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "  rollout_iterations: int = 2000\n",
        "  model_name: str = \"facebook/opt-350m\"\n",
        "  epochs: int = 1\n",
        "  num_steps: int = 100\n",
        "  batch_size : int = 2\n",
        "  max_new_tokens : int = 600\n",
        "  temperature: float = 0.7\n",
        "  kl_coeff : float = 0.1\n",
        "  gamma : float = 0.95\n",
        "  lambda_v : float = 0.99\n",
        "  clip_epsilon: float = 0.2, # the surrogate clipping coefficient\n",
        "  ent_coef: float = 0.01, # entroy coefficient controlling the exploration factor C2\n",
        "  vf_coef: float = 0.5, # value function controlling value estimation importance C1\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "4xDe-Cff56WI"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def get_data(data):\n",
        "  indexes = torch.randint(len(data), (config.batch_size,))\n",
        "  return data[indexes]"
      ],
      "metadata": {
        "id": "gDuJ0a7150pl"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make something to save the generated tokens.\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "class Trajectories(Dataset):\n",
        "  def __init__(self, logprobs=None, actions=None, rewards=None, values=None, advantages=None, end=None, returns=None):\n",
        "    self.actions = actions\n",
        "    self.rewards = rewards\n",
        "    self.values = values\n",
        "    self.advantages = advantages\n",
        "    self.logprobs = logprobs\n",
        "    self.end = end # end of generation, after this index all tokens are pad token\n",
        "    self.returns = returns\n",
        "  def __getitem__(self,idx):\n",
        "    return self.logprobs[idx], self.actions[idx], self.rewards[idx], self.values[idx], self.advantages[idx],self.end[idx], self.returns\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.logprobs)\n",
        "\n",
        "  def add(self,logprobs, actions, rewards, values, advantages, end):\n",
        "    self.actions = torch.cat((self.actions, actions), dim=0) if self.actions is not None else actions\n",
        "    self.rewards = torch.cat((self.rewards, rewards), dim=0) if self.rewards is not None else rewards\n",
        "    self.values = torch.cat((self.values, values), dim=0) if self.values is not None else values\n",
        "    self.advantages = torch.cat((self.advantages, advantages), dim=0) if self.advantages is not None else advantages\n",
        "    self.logprobs = torch.cat((self.logprobs, logprobs), dim=0) if self.logprobs is not None else logprobs\n",
        "    self.end = torch.cat((self.end, end), dim=0) if self.end is not None else end\n",
        "    self.returns = torch.cat((self.returns, returns), dim=0) if self.returns is not None else returns\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "65wSghLo0dKD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajectories = agent.generate(**inputs)"
      ],
      "metadata": {
        "id": "jQbVmDG5LM5i"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z10USlC0Mwf4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logits, values = agent(trajectories.to(device))\n",
        "  ref_model_logits = model(trajectories)"
      ],
      "metadata": {
        "id": "AhTu33OxQh4D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HztEO0FvQhrz",
        "outputId": "8f4ec184-08f8-4c0e-c97f-3851a4599588"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 517, 50272])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B,T = trajectories.shape\n",
        "B,T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzVu-B_VRIag",
        "outputId": "589ec3f9-d9ab-4b20-b6bc-cb5cdaa6d18a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 517)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rewards = torch.randint(100, (B,), dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "PNkBqV7JRSiZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMQuKb4iLmD_",
        "outputId": "02fffb48-8ea2-4789-cc12-f24b62f73480"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([77, 34, 82], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = torch.log_softmax(logits, dim=-1)\n",
        "logprobs = torch.gather(logits[:,:-1,:], dim =-1, index = trajectories[:,1:].unsqueeze(dim=-1)).squeeze()"
      ],
      "metadata": {
        "id": "1fSpAoHfSd4c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_model_logits = torch.log_softmax(ref_model_logits.logits, dim=-1)\n",
        "ref_model_logprobs = torch.gather(ref_model_logits[:,:-1,:], dim =-1, index = trajectories[:,1:].unsqueeze(dim=-1)).squeeze()"
      ],
      "metadata": {
        "id": "KyWGg6-eUeWF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = trajectories.not_equal(tokenizer.pad_token_id).long()"
      ],
      "metadata": {
        "id": "ABKjA6FXUeTa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = inputs['input_ids'].shape[1] - 1\n",
        "start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcbajA6AL2pN",
        "outputId": "395ed517-0e2f-439a-c258-32471e9d48ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end = attention_mask[:,start+1:].sum(dim=-1)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmzkKAEBO2H4",
        "outputId": "c2a7dff7-1ff5-4d0d-b045-a8abdbc550f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([512, 512, 512], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ym4xV6aMWWYP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6LmmR3BW0ql"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "token_rewards = -0.1 * logprobs - ref_model_logprobs"
      ],
      "metadata": {
        "id": "2O7md5ApRdEm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jWuovHjPc_g",
        "outputId": "f21e035b-80f0-44a7-e979-a326c83eec8b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([512, 512, 512], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSCXHVYaRKif",
        "outputId": "748ac304-60dd-4749-81c8-25014ae64fd6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.6187e+00, 2.9436e+00, 2.5706e-03,  ..., 6.0164e-03, 1.1513e-04,\n",
              "         1.4091e-03],\n",
              "        [4.7907e+00, 2.8869e+00, 8.0073e+00,  ..., 1.3325e-03, 8.0655e-04,\n",
              "         2.2269e-01],\n",
              "        [8.9809e+00, 2.0089e+00, 1.3762e+00,  ..., 1.0015e-02, 2.2749e-04,\n",
              "         6.1124e-03]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(B):\n",
        "  # token_rewards[t, start + end[t]] = torch.tensor(rewards[t]).clone().detach().float()\n",
        "  token_rewards[t, start + end[t] -1] = rewards[t].float()"
      ],
      "metadata": {
        "id": "Y05KOs05VN6_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_rewards.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYI_EyXVU6K",
        "outputId": "51f0ae5a-be14-402a-dea8-3e89ff13a391"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 516])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = values[:,:-1].squeeze()"
      ],
      "metadata": {
        "id": "mv-faURdVU0a"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ufHby2NaggC",
        "outputId": "bd1dbd55-1f08-40e3-a529-789b80de285e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 516])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZLjKUF_cYnk",
        "outputId": "ad827aa2-c9ef-45a3-f4ad-865273cef02a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Config(rollout_iterations=2000, model_name='facebook/opt-350m', epochs=1, num_steps=100, batch_size=8, max_new_tokens=600, temperature=0.7, kl_coeff=0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gae(rewards, values):\n",
        "  last_value = 0\n",
        "  last_advantage = 0\n",
        "  advantages = torch.zeros_like(values).to(rewards.device)\n",
        "\n",
        "  for t in reversed(range(rewards.shape[1])):\n",
        "    delta = rewards[:,t] + config.gamma*last_value - values[:,t]\n",
        "    advantages[:,t] = delta + config.lambda_v* config.gamma*last_advantage\n",
        "    last_value = values[:,t]\n",
        "    last_advantage = advantages[:,t]\n",
        "\n",
        "  returns = advantages + values\n",
        "\n",
        "  return advantages, returns"
      ],
      "metadata": {
        "id": "7BvuZbDqaw99"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Vt47mh6d5_8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantages, returns = gae(token_rewards, values)"
      ],
      "metadata": {
        "id": "Z4VvBlRJduBg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantages.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYKqM9QWeAIF",
        "outputId": "45234b81-b336-4e4b-a8e7-400cdc05d15d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 516])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectories.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58KgV2CeiMM3",
        "outputId": "88bd51f8-0b6f-46dd-c924-88ff3578c4c1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 516])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzqef6STlFHD",
        "outputId": "21a89023-6efd-4c06-fb04-9725d0bab450"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([512, 512, 512], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rollouts = Trajectories()\n",
        "\n",
        "rollouts.add(trajectories, token_rewards, values, advantages, logprobs, end,returns)"
      ],
      "metadata": {
        "id": "ANhtIQVReBt2"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_data = get_data(rollouts)"
      ],
      "metadata": {
        "id": "BZWex6lOlJms"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(retrieved_data[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWbusj3KlJjT",
        "outputId": "aac3667d-dfb7-4eb9-f6d5-92ecfe02a28b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([512, 512], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## NOW lets do the generation and the update.\n",
        "\n",
        "# we generate from the updated model.\n",
        "\n",
        "r_actions, r_rewards, r_values, r_advantages, r_logprobs, r_end, r_returns = retrieved_data"
      ],
      "metadata": {
        "id": "xgltY_fQlJgK"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since we want to train this model, we don't do torch.no_grad() here,\n",
        "\n",
        "new_model_logits, new_model_values = agent(r_actions)\n",
        "new_mode_logits = torch.log_softmax(new_model_logits, dim =-1)\n",
        "\n",
        "\n",
        "\n",
        "# now we have everything we needd\n",
        "\n"
      ],
      "metadata": {
        "id": "X8vEggIrlufF"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_mode_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwS811SatrZm",
        "outputId": "60b1ac22-3361-4dea-9b83-6981fe150a85"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 516, 50272])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_logprobs = torch.gather(new_model_logits[:,:-1, :], dim=-1, index=r_actions[:,1:].unsqueeze(-1)).squeeze() # will be 516"
      ],
      "metadata": {
        "id": "d1_H_nZYtmg4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_logprobs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFc7EF0yraIP",
        "outputId": "ea8f3813-883a-4306-b23e-224ec234d935"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 516])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_mask = torch.zeros_like(new_model_logprobs)\n",
        "\n",
        "for t in range(config.batch_size):\n",
        "  # generate loss mask from start and end\n",
        "\n",
        "  loss_mask[t: start: end[t]] = 1\n",
        "\n",
        "\n",
        "new_model_logprobs_flatten = (new_model_logprobs * loss_mask).view(-1)\n",
        "new_model_values_flatten = (new_model_values * loss_mask).view(-1)\n",
        "r_logprobs_flatten = (r_logprobs * loss_mask).view(-1)\n",
        "r_advantages_flatten = (r_advantages * loss_mask).view(-1)\n",
        "\n",
        "ppo_loss = loss_clip(r_logprobs_flatten, new_model_logprobs_flatten, r_advantages_flatten)\n",
        "value_func_loss = loss_vf( r_returns, new_model_values_flatten)\n",
        "\n",
        "loss = ppo_loss + value_func_loss\n",
        "l\n",
        "# define the optimizer\n",
        "# loss backward\n",
        "# optimizer step\n",
        "\n",
        "# that should be it, recheck everything once,\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEMLiVAFt-iR",
        "outputId": "7447b7b7-9cf1-4543-e3fa-84dd844fa123"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 516])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_vf(\n",
        "    mb_oldreturns,  # mini batch of old returns collected during the rollout\n",
        "    mb_newvalues    # minibach of values calculated by the new value function\n",
        "):\n",
        "    \"\"\"\n",
        "    enforcing the value function to give more accurate estimates of returns\n",
        "    \"\"\"\n",
        "    mb_newvalues = mb_newvalues.view(-1)\n",
        "    loss = 0.5 * ((mb_newvalues - mb_oldreturns) ** 2).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "-G6Cq0aVzsxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_clip(\n",
        "    mb_oldlogporb,     # old logprob of mini batch actions collected during the rollout\n",
        "    mb_newlogprob,     # new logprob of mini batch actions created by the new policy\n",
        "    mb_advantages      # mini batch of advantages collected during the the rollout\n",
        "):\n",
        "    \"\"\"\n",
        "    policy loss with clipping to control gradients\n",
        "    \"\"\"\n",
        "    ratio = torch.exp(mb_newlogprob - mb_oldlogporb)\n",
        "    policy_loss = -mb_advantages * ratio\n",
        "    # clipped policy gradient loss enforces closeness\n",
        "    clipped_loss = -mb_advantages * torch.clamp(ratio, 1 - configs.clip_epsilon, 1 + configs.clip_epsilon)\n",
        "    pessimistic_loss = torch.max(policy_loss, clipped_loss).mean()\n",
        "    return pessimistic_loss"
      ],
      "metadata": {
        "id": "CoBSuWrnlubd"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rollout(tokenized_dataset):\n",
        "  # Generate samples from the tokenized_dataset, and calculate v,r,a\n",
        "  for i in range(config.rollout_iterations):\n",
        "    to_generate_data = get_data(tokenized_dataset)\n",
        "\n",
        "    trajectories = agent.generate(**to_generate_data)\n",
        "    logits, values = agent(trajectories) # (B,T,vocab_len), (B,T,1))\n",
        "    rewards = torch.zeros(values.shape[0],values.shape[1])\n",
        "\n",
        "    # now find the reward,\n",
        "    output = tokenizer.decode(generated_data)\n",
        "    # mask = to_generate_data\n",
        "    total_reward = reward_model(output) # B\n",
        "\n",
        "\n",
        "    #incorporate kl penalty\n",
        "    # reference model\n",
        "    ref_model_data = model.generate(**to_generate_data, max_new_tokens=config.max_new_tokens, output_logits=True, return_dict_in_generate=True) #(B,T)\n",
        "    ref_model_probs = torch.log_softmax(ref_model_data.logits, dim=-1)\n",
        "    ref_data_logprobs = torch.gather(ref_model_probs, dim=-1, index=ref_model_data) # get the logprobs for generated data\n",
        "\n",
        "    # training model\n",
        "    probs = torch.log_softmax(logits, dim=-1)\n",
        "    new_data_logprobs = torch.gather(probs, dim=-1, index=ref_model_data)\n",
        "\n",
        "    rewards =  new_data_logprobs - ref_data_logprobs\n",
        "\n",
        "    # advantage GAE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HW5KJTxyyFiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UWICqgRPZ8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}